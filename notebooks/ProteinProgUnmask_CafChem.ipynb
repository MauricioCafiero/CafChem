{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CafChem tools for progressive unmasking of proteins\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MauricioCafiero/CafChem/blob/main/notebooks/ProteinProgUnmask_CafChem.ipynb)\n",
        "\n",
        "## This notebook allows you to:\n",
        "- load a protein sequence\n",
        "- specify which residues to mask\n",
        "- ESM model unmasks residues; code then chooses the unmasked residue with the highest probability and adds it to the chain.\n",
        "- chain with newly unmasked residue is passed through the model again, and the new unmasked residue with the highest probability os added to the chain.\n",
        "- etc.\n",
        "- tools to compare old an new chains.\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "- Runs quickly on an L4 GPU"
      ],
      "metadata": {
        "id": "8fG1Qee4XjzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import libraries"
      ],
      "metadata": {
        "id": "mr9QJnZYYY68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q py3Dmol\n",
        "!pip install -q \"fair-esm[esmfold]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESYsBWvPLs55",
        "outputId": "37d4bb79-a6e7-4b60-c38f-c3906b41e594"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.3/510.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eh0ixvcOLdvc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, EsmModel, EsmForMaskedLM, EsmForSequenceClassification\n",
        "import torch\n",
        "from torch import inf\n",
        "import py3Dmol\n",
        "import requests\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import esm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define functions"
      ],
      "metadata": {
        "id": "U1_Qu1swYeLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_to_three(one_seq):\n",
        "  '''\n",
        "  Convert one-letter code to three-letter code\n",
        "  Input: one-letter code\n",
        "  Output: three-letter code\n",
        "  '''\n",
        "  rev_aa_hash = {\n",
        "      'A': 'ALA',\n",
        "      'R': 'ARG',\n",
        "      'N': 'ASN',\n",
        "      'D': 'ASP',\n",
        "      'C': 'CYS',\n",
        "      'Q': 'GLN',\n",
        "      'E': 'GLU',\n",
        "      'G': 'GLY',\n",
        "      'H': 'HIS',\n",
        "      'I': 'ILE',\n",
        "      'L': 'LEU',\n",
        "      'K': 'LYS',\n",
        "      'M': 'MET',\n",
        "      'F': 'PHE',\n",
        "      'P': 'PRO',\n",
        "      'S': 'SER',\n",
        "      'T': 'THR',\n",
        "      'W': 'TRP',\n",
        "      'Y': 'TYR',\n",
        "      'V': 'VAL'\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    three_seq = rev_aa_hash[one_seq]\n",
        "  except:\n",
        "    three_seq = 'X'\n",
        "\n",
        "  return three_seq\n",
        "\n",
        "class gen_mask_fill():\n",
        "  '''\n",
        "  Class to generate masks and fill them with ESM predictions\n",
        "  '''\n",
        "  def __init__(self, checkpoint: str, seq: list, res_to_mask: list[str]):\n",
        "    '''\n",
        "    Constructor for mask filling\n",
        "    Input:\n",
        "    - checkpoint: path to ESM model\n",
        "    - seq: sequence to mask\n",
        "    - res_to_mask: list of residues to mask\n",
        "    '''\n",
        "    self.checkpoint = checkpoint\n",
        "    self.seq = seq\n",
        "    self.res_to_mask = res_to_mask\n",
        "    self.natural_residues = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "                             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "\n",
        "  def start_model(self):\n",
        "    '''\n",
        "    Start ESM model and tokenizer\n",
        "    '''\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
        "    self.model = EsmForMaskedLM.from_pretrained((self.checkpoint))\n",
        "\n",
        "  def mask_tokens(self):\n",
        "    '''\n",
        "    Mask tokens in sequence\n",
        "    Output:\n",
        "    - seq_ids: sequence of tokens\n",
        "    - masked_chain: masked sequence\n",
        "    - masked_chain_ids: masked sequence of tokens\n",
        "    '''\n",
        "    self.seq_ids = self.tokenizer(''.join(self.seq))['input_ids']\n",
        "\n",
        "    masked_chain = []\n",
        "    num_masked = 0\n",
        "    for i, token in enumerate(self.seq):\n",
        "      if token in self.res_to_mask:\n",
        "        masked_chain.append('<mask>')\n",
        "        num_masked += 1\n",
        "      else:\n",
        "        masked_chain.append(token)\n",
        "\n",
        "    self.num_masked = num_masked\n",
        "    self.masked_chain = masked_chain\n",
        "    self.masked_chain_ids = self.tokenizer(''.join(masked_chain))['input_ids']\n",
        "\n",
        "    return self.seq_ids, self.masked_chain, self.masked_chain_ids\n",
        "\n",
        "  def unmask(self):\n",
        "    '''\n",
        "    Unmask tokens in sequence; fills in mask with highest probability, then re-runs\n",
        "    ummasking model on remaining masked tokens and repeats until all are unmasked.\n",
        "    Output:\n",
        "    - masked_chain: unmasked sequence\n",
        "    '''\n",
        "    for k in range(self.num_masked):\n",
        "      model_out = self.model(**self.tokenizer(text = ''.join(self.masked_chain), return_tensors='pt'))\n",
        "\n",
        "      masked_probs = []\n",
        "      for i, row in enumerate(model_out.logits[0][1:-1]):\n",
        "        if self.masked_chain[i] == '<mask>':\n",
        "          probs = torch.softmax(row.detach().clone(), dim=0)\n",
        "          best_prob = torch.argmax(probs).detach().clone().item()\n",
        "          masked_probs.append((probs[best_prob],i+1))\n",
        "\n",
        "      masked_probs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "      new_token = self.tokenizer.decode([masked_probs[0][1]])\n",
        "      if new_token not in self.natural_residues:\n",
        "        new_token = 'G'\n",
        "      self.masked_chain[masked_probs[0][1]-1] = new_token\n",
        "\n",
        "    return self.masked_chain\n",
        "\n",
        "  def compare_seqs(self):\n",
        "    '''\n",
        "    Compare original and new sequences\n",
        "    Output:\n",
        "    - chain: original sequence\n",
        "    - new_seq: new sequence\n",
        "    '''\n",
        "    self.new_seq = ''.join(self.masked_chain)\n",
        "    self.chain = ''.join(self.seq).replace('<cls>','').replace('<eos>','')\n",
        "    print(f\"Original: {self.chain}\")\n",
        "    print(f\"Novel   : {self.new_seq}\")\n",
        "\n",
        "    i = 1\n",
        "    for char_o, char_n in zip(self.seq,self.new_seq):\n",
        "      if char_o != char_n:\n",
        "        print(f\"Residue {i} changed {one_to_three(char_o)} --> {one_to_three(char_n)}.\")\n",
        "      i += 1\n",
        "\n",
        "    return self.chain, self.new_seq\n",
        "\n",
        "  def compare_seqs_naive(self):\n",
        "    '''\n",
        "    Compare original and new sequences by % of differences\n",
        "    Output:\n",
        "    - chain: original sequence\n",
        "    - new_seq: new sequence\n",
        "    '''\n",
        "    self.new_seq = ''.join(self.masked_chain)\n",
        "\n",
        "    self.chain = ''.join(self.seq).replace('<cls>','').replace('<eos>','')\n",
        "    print(f\"Original: {self.chain}\")\n",
        "    print(f\"Novel   : {self.new_seq}\")\n",
        "\n",
        "    num_diff = 0\n",
        "    for char_o, char_n in zip(self.seq,self.new_seq):\n",
        "\n",
        "      if char_o != char_n:\n",
        "        num_diff += 1\n",
        "\n",
        "    print(f\"Number of differences: {num_diff} out of {len(self.seq)}\")\n",
        "    print(f\"Percentage of differences: {num_diff/len(self.seq):.3f}\")\n",
        "\n",
        "    return self.chain, self.new_seq"
      ],
      "metadata": {
        "id": "3C7GGgt1LlAc"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unmask proteins"
      ],
      "metadata": {
        "id": "hWfaJsZiYhVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgt_mask = gen_mask_fill(checkpoint = 'facebook/esm2_t33_650M_UR50D', seq = 'HXEGTFTSDVSSYLEGQAAKEFIAWLVRGRG', res_to_mask = ['G'])\n",
        "sgt_mask.start_model()"
      ],
      "metadata": {
        "id": "yrEdszJ1MfvF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_ids, masked_chain, masked_chain_ids = sgt_mask.mask_tokens()\n",
        "print(seq_ids)\n",
        "print(masked_chain_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRawEc9lMpzC",
        "outputId": "f6fc5285-bf78-43ac-e877-6a163400ea82"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 21, 24, 9, 6, 11, 18, 11, 8, 13, 7, 8, 8, 19, 4, 9, 6, 16, 5, 5, 15, 9, 18, 12, 5, 22, 4, 7, 10, 6, 10, 6, 2]\n",
            "[0, 21, 24, 9, 32, 11, 18, 11, 8, 13, 7, 8, 8, 19, 4, 9, 32, 16, 5, 5, 15, 9, 18, 12, 5, 22, 4, 7, 10, 32, 10, 32, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(masked_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUCHnRNMN6k_",
        "outputId": "fd2f1878-7ed0-440e-92f3-73731eed48fb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'X', 'E', '<mask>', 'T', 'F', 'T', 'S', 'D', 'V', 'S', 'S', 'Y', 'L', 'E', '<mask>', 'Q', 'A', 'A', 'K', 'E', 'F', 'I', 'A', 'W', 'L', 'V', 'R', '<mask>', 'R', '<mask>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chain = sgt_mask.unmask()\n",
        "print(new_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDV0BnHoMy-s",
        "outputId": "c1c84b5c-7819-4bcf-8f1f-f767a521f84a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'X', 'E', 'L', 'T', 'F', 'T', 'S', 'D', 'V', 'S', 'S', 'Y', 'L', 'E', 'Q', 'Q', 'A', 'A', 'K', 'E', 'F', 'I', 'A', 'W', 'L', 'V', 'R', 'G', 'R', 'G']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig, new = sgt_mask.compare_seqs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCsaTEXfWWbN",
        "outputId": "aa345ab5-2844-4279-9cf9-8b9db82a6a94"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: HXEGTFTSDVSSYLEGQAAKEFIAWLVRGRG\n",
            "Novel   : HXELTFTSDVSSYLEQQAAKEFIAWLVRGRG\n",
            "Residue 4 changed GLY --> LEU.\n",
            "Residue 16 changed GLY --> GLN.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig, new = sgt_mask.compare_seqs_naive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzPXsz3YNIPW",
        "outputId": "9e057f44-e974-4a9a-c687-b80e6adb6225"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: HXEGTFTSDVSSYLEGQAAKEFIAWLVRGRG\n",
            "Novel   : HXELTFTSDVSSYLEQQAAKEFIAWLVRGRG\n",
            "Number of differences: 2 out of 31\n",
            "Percentage of differences: 0.065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhFkhZQQVE4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}